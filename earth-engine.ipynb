{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import certifi\n",
    "import os\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained model from TensorFlow Hub\n",
    "model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (300, 300))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Function to run inference\n",
    "def run_inference(image_path, model):\n",
    "    img = load_image(image_path)\n",
    "    results = model(img)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "image_path = '/Users/emilyzhao/STS/Screenshot 2024-07-13 at 4.48.55â€¯PM.png'\n",
    "results = run_inference(image_path, model)\n",
    "\n",
    "# Extracting the detection results\n",
    "detection_boxes = results['detection_boxes'][0].numpy()\n",
    "detection_scores = results['detection_scores'][0].numpy()\n",
    "detection_classes = results['detection_classes'][0].numpy()\n",
    "\n",
    "# Display the results\n",
    "for i in range(len(detection_boxes)):\n",
    "    if detection_scores[i] > 0.5:\n",
    "        print(f\"Detected object {i} with score {detection_scores[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest (Long Island, New York)\n",
    "long_island = ee.Geometry.Polygon(\n",
    "    [[[-73.935242, 40.496044],\n",
    "      [-73.935242, 41.052613],\n",
    "      [-72.533539, 41.052613],\n",
    "      [-72.533539, 40.496044]]])\n",
    "\n",
    "# Define the time period\n",
    "start_date = '2020-09-01'\n",
    "end_date = '2020-09-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentinel-2 image collection for the specified period and location\n",
    "image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(long_island) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))  # Filter images with less than 20% cloud coverage\n",
    "\n",
    "# Select the first image for demonstration purposes\n",
    "image = image_collection.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentinel-2 image collection for the specified period and location\n",
    "image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(long_island) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "\n",
    "# Select the bands of interest (e.g., RGB)\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "# Function to extract pixel values\n",
    "def get_pixel_values(image, region, scale=10):\n",
    "    # Reduce the region and get the pixel values\n",
    "    return image.select(bands).reduceRegion(\n",
    "        reducer=ee.Reducer.toList(),\n",
    "        geometry=region,\n",
    "        scale=scale,\n",
    "        bestEffort=True\n",
    "    ).getInfo()\n",
    "\n",
    "# Iterate over the image collection and extract pixel values\n",
    "pixel_values = []\n",
    "for image in image_collection.toList(image_collection.size()).getInfo():\n",
    "    img = ee.Image(image['id'])\n",
    "    pixel_values.append(get_pixel_values(img, long_island))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentinel-2 image collection for the specified period and location\n",
    "image_collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(long_island) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n",
    "\n",
    "# Select the bands of interest (e.g., RGB)\n",
    "bands = ['B4', 'B3', 'B2']\n",
    "\n",
    "# Function to extract pixel values\n",
    "def get_pixel_values(image, region, scale=10):\n",
    "    return image.select(bands).reduceRegion(\n",
    "        reducer=ee.Reducer.toList(),\n",
    "        geometry=region,\n",
    "        scale=scale,\n",
    "        bestEffort=True,\n",
    "        maxPixels=1e8\n",
    "    ).getInfo()\n",
    "\n",
    "# Get a list of images\n",
    "image_list = image_collection.toList(image_collection.size())\n",
    "\n",
    "# Extract pixel values from the first image in the list for demonstration\n",
    "first_image = ee.Image(image_list.get(0))\n",
    "pixel_values = get_pixel_values(first_image, long_island)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def prepare_pixel_data(pixel_values, image_shape=(300, 300)):\n",
    "    # Ensure pixel_values is a dictionary containing 'B4', 'B3', and 'B2' keys\n",
    "    red_band = np.array(pixel_values['B4'])\n",
    "    green_band = np.array(pixel_values['B3'])\n",
    "    blue_band = np.array(pixel_values['B2'])\n",
    "\n",
    "    # Stack the bands along the last dimension\n",
    "    img = np.stack([red_band, green_band, blue_band], axis=-1)\n",
    "\n",
    "    # Check the shape\n",
    "    print(f\"Extracted image shape: {img.shape}\")\n",
    "\n",
    "    # Normalize pixel values\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Ensure the image is resized to the model's input shape\n",
    "    img_resized = cv2.resize(img, (image_shape[1], image_shape[0]))\n",
    "\n",
    "    # Expand dimensions to match model input\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "\n",
    "    return img_resized\n",
    "\n",
    "processed_data = prepare_pixel_data(pixel_values, image_shape=(300, 300))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
